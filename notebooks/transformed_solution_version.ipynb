{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5279386-3cff-4c20-9cf4-bb9d02d2aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6e55b-36bf-4088-bcd7-4301f17d2ea4",
   "metadata": {},
   "source": [
    "# Notation\n",
    "\n",
    "This notebook solves $\\frac{\\mathrm{d}^2 x}{\\mathrm{d}t^2} = F$, for constant $F$.\n",
    "\n",
    "This equation does, of course, have a 2D space of solutions. This notebook finds the solution that minimizes the $L^2$ norm between the solution and a set of datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f558b4-aa0f-4a8f-aa36-e91cc9f50395",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b29c89-ca91-4ae2-9031-904fa7b4bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can edit anything in this cell.\n",
    "# If you do so, you should re-run the whole notebook.\n",
    "\n",
    "h = 0.01  # Grid resolution\n",
    "rng_seed_data = 1234  # Used for data generation\n",
    "sigma = 0.0  # Noise level for data generation\n",
    "N_samples = 10  # Number of datapoints to 'measure' from the 'true' curve\n",
    "F = -10  # Force. Constant in this version. Chosen to be close to free-fall in SI units.\n",
    "\n",
    "x0 = 0.5  # Initial condition for the true solution.\n",
    "v0 = 0.1  # Initial condition for the true solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe83a2-4b30-43a8-9d3c-c19196e52269",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195e0e9-6302-4e12-84f4-9b60ee7ac9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grid = np.arange(0, 1, h)  # Useful to have this for plotting.\n",
    "N_grid = t_grid.shape[0]  # Number of points in this discretized grid over t.\n",
    "x_true_grid = x0 + t_grid*v0 + 0.5*F*t_grid**2  # True solution curve.\n",
    "\n",
    "rng_data = np.random.RandomState(rng_seed_data)  # Instantiate the RNG in the same cell that we will do all the calls.\n",
    "idx_samples = rng_data.choice(N_grid, size=N_samples, replace=False)  # Choose which datapoints will will 'measure'\n",
    "idx_samples = np.sort(idx_samples)\n",
    "x_noise = rng_data.normal(scale=sigma, size=(N_samples,))  # Sample noise to be added to our datapoints.\n",
    "t_samples = t_grid[idx_samples]  # Used only for plotting in this example\n",
    "x_samples = x_true_grid[idx_samples] + x_noise  # Noisy datapoints\n",
    "del rng_data  # Delete to prevent re-use of this RNG in the solution section.\n",
    "\n",
    "# Plot the generated data\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t_grid, x_true_grid, ls='-', marker='none')\n",
    "ax.plot(t_samples, x_samples, ls='none', marker='o', alpha=0.7)\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x(t)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c696d456-b9f6-4d24-9f81-8212d6462f26",
   "metadata": {},
   "source": [
    "# Numerical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4aed3-2dcc-4bcf-94e4-06b6740a638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters / initialization\n",
    "\n",
    "# Parameters in this cell are specific to the numerical solution method.\n",
    "# If you change any of these, you do not need to re-run data generation.\n",
    "\n",
    "# The lines below define a linear transformation from the natural space of the problem,\n",
    "# i.e. the vector [x(t_0), x(t_1), ..., x(t_{N-1})],\n",
    "# to a potentially different space [z_0, z_1, ..., z_{N-1}] in which the ODE will be solved by gradient descent.\n",
    "# To solve this in the original space, set A_x2z to be the identity matrix.\n",
    "A_x2z = np.zeros((N_grid, N_grid), dtype=np.float64)\n",
    "A_x2z[0, 0] = 1.0  # z_0 = z(t_0)\n",
    "for i in range(1, N_grid):\n",
    "    # z_i = x(t_i) - x(t_{i-1}) for i > 0\n",
    "    A_x2z[i, i] = 1.0\n",
    "    A_x2z[i, i-1] = -1.0\n",
    "\n",
    "\n",
    "N_iter = 1000  # Number of iterations of optimization.\n",
    "\n",
    "# Initialize the solution grid.\n",
    "# I don't believe there is any benefit to using random initialization, since this problem does not\n",
    "# have the same requirement for symmetry-breaking that exists with the hidden neurons of a neural network.\n",
    "z_solution_grid = np.zeros(N_grid, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# Define the optimizer.\n",
    "# This problem seems to benefit from using a second-order optimizer (which LBFGS is), and I believe that\n",
    "# is due to the Hessian of loss_ODE (see below for defintion) having a very large condition number.\n",
    "optimizer = torch.optim.LBFGS(lr=1, history_size=10, params=[z_solution_grid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7acd08-5c87-46ab-9ee3-308f1e597cf7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
